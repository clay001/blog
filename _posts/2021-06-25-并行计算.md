---
layout: post
title: "并行计算"
date: 2021-06-25 17:37:00
image: '/assets/img/'
description: '未来工作的并行知识'
tags:
- CUDA
- NVIDIA
categories:
- Work related
twitter_text: 'Do you know these?'

---

## To You

When I think of you, I'm reminded of the beautiful plains of Iowa.The distance between us is breaking my spirit. My time and experiences without you are meaningless to me. Falling in love with you was the easiest thing I have ever done. Nothing matters to me but you.And everyday I am alive, I'm aware of this. I loved you the day I met you, I love you today, and I will love you to rest of my life.

## 现代CPU的架构

现代的架构包括：流水线，分支预测，超标量，乱序执行（OoO），存储器层次，矢量操作，多核处理

CPU是执行指令，处理数据的器件。包含上亿个晶体管，对于一个目标程序，其优化目标是CPI（每条指令的时钟数）和时钟周期

桌面应用中，大部分的指令其实是分支判断或者访存交互，用于矢量运算的其实比较少

摩尔定律：芯片的集成密度每两年翻一番，成本下降一半。 硅基的芯片已经接近物理极限了。

取址 -> 译码 -> 执行 -> 访存 -> 写回

Bypassing（旁路）：用于加快流水线的等待

Stall（停滞）：等待策略

Branches（分支）：现代分支预测的准确率能达到高于九成的水平，分支断定是直接把所有的事情都做一遍

超标量提升IPC（instruction per cycle），增加流水线宽度

存储器层次：硬盘驱动器（HDD），闪存（Flash），动态随机存取存储器（DRAM），静态随机存取存储器（SRAM）

并行分为指令级的并行（乱序执行，超标量），数据级的并行（矢量运算），线程级的并行（同步多线程，多核）

多线程处理同一块数据的时候就要涉及到锁，一致性（谁是对的）和同一性（什么样是对的）

主频的定义是中央处理器的内核在工作时的单位时钟内的频率，举个例子来说，主频是2GHz的CPU在单位时钟内处理一个运算的时间要比主频是1GHz的CPU少用一倍的时间。

带宽又叫频宽，是指在固定的的时间可传输的资料数量，亦即在传输管道中可以传递数据的能力。

## 并行编程模型

共享存储模型，线程模型，消息传递模型，数据并行模型

（比如open MP，MPI，SPMD，MPMD）

amdahl law：1/1-p（p是可以被并行化的部分），1/（P/N+S）（S表示串行部分，P表示并行部分，N表示处理器的数量）

CPU-GPU互动模型：通过PCIE总线连接（8GB-16GB/s）

GPU存储器层次架构：内存，显存都有不同的分级

GPU线程组织模型：Grid，Block，Warp，Thread

映射调度关系：线程映射到GPU的线程处理器上，线程块映射到多处理器上。



## GPU

cuda配合visual studio，安装完成后是一个corporation的文件夹（包含samples，toolkit，Nsight，tool extension）

FLOPS ：每秒钟执行的浮点数操作，GFLOPS（10的九次方），TFLOPS（1000GFLOPS）

GPU是一个异构的多处理器芯片，为图形图像处理优化。

优化的思路：1. 精简多核，多个程序片元共享指令流   2. 增加ALU宽度，进行SIMD（单指令多数据的思路）3. 大量的独立片元相互切换来掩藏延时（上下文存储池） 

ALU只能处理相同的指令流，但是因为上下文存储池可以是有多组数据，所以可以加载多路的指令流。不同的ALU可以看作是不同的程序片元，所以总的指令流数乘以ALU个数就是可以处理的并发程序片元数量，联合上主频（这里要除2暂时不知道为什么）可以的得到FLOPS的性能参数。

在GPU中，核被称为SM（流多处理器），每一个ALU被称为一个cuda核。

GTX480（Fermi）中在每个核中把ALU分为两组。GTX680（Kepler）架构中，192个ALU分为4个小组。GK110有15个核，每个核有192个ALU。

缓存分级，L123，容量依次增大，速度依次降低。基本上性能低下是因为带宽受限。

GPU中的SIMT（单指令多线程，线程切换掩藏延时）

GPGPU是传统图形处理GPU在通用计算领域上的推广，07年CUDA（统一计算设备架构）诞生，08年openCL规范出现

## 名词解释

chiplet 技术：就是像搭积木一样，把一些预先生产好的实现特定功能的芯片裸片（die）通过先进的集成技术（比如 3D integration）集成封装在一起形成一个系统芯片。属于SiP。

SoC：System on Chip是将系统关键部件集成在一块芯片上。

SiP：System in Package是从封装的立场出发，对不同芯片进行并排或叠加的封装方式，将多个具有不同功能的有源电子元件与可选无源器件，以及诸如MEMS（微机电系统）或者光学器件等其他器件优先组装到一起。

EDA软件：简单的来讲就是设计电子芯片，电路板必需的软件，涵盖了 IC 设计、电路板设计布线、验证和仿真，测试等所有方面。

芯片是最大的统称，只要是包含了各种半导体元件的集成电路都是芯片。
处理器是芯片的一种，指可以执行程序的逻辑机器。电脑里用的CPU其实名字是中央处理器，是处理器的一种。其他还可以有诸如图像处理器，数字信号处理器等。
内核有多种概念，在计算机硬件方面的内核指处理器的内部核心，包装在一个元件中的独立处理单元，称为core。在计算机软件方面指操作系统最基本的部分，负责管理系统资源和提供对系统资源的访问，称为kernel。

Host：主机端，通常指CPU

Device：设备端，通常指GPU。主机端和设备端拥有各自的存储器

Kernel：数据并行处理函数。







