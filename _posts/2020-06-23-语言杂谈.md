---
layout: post
title: "Current research(4)"
date: 2020-06-23 15:58:34
image: '/assets/img/'
description: '语言杂谈'
tags:
- note
categories:
- note
twitter_text: 'talk something about language'
---

## Everyday sentence

Time is like a river, the left bank is unable to forget the memories, right is worth grasp the youth, the middle of the fast flowing, is the sad young faint. There are many good things, buttruly belong to own but not much. See the courthouse blossom,honor or disgrace not Jing, hope heaven Yunjuanyunshu, has no intention to stay. In this round the world, all can learn to use a normal heart to treat all around, is also a kind of realm!

## 聊聊python，java

python创造的最初定位就是所有人都能使用的语言，所以它并不追求速度，而是追求一种哲理，一种以一敌万的哲学。加上目前有了Scipy/ numpy优化，还可以用Cython这种编译器加速，所以效率也不是这么严重的问题了。

java则是第一个系统提供模块化设计的语言。这两种语言其实在某种程度上减轻了炒掉一个程序员的代价，之前的 lisp/ C / C++程序员写的上万行的代码逻辑是很难被接手的，而这两种语言出现以后，可以把一个大的任务，分成小块分配给程序员，只需要定义接口和虚拟类即可。而且新手和老手程序员在使用这两种语言的时候并不会有太大的差距，因为比如 java 要优化就必须要对JVM进行优化，这样的难度其实是很大的

## Scala的出场

上面的种种问题就引出了Scala，Scala提供一整套工具让程序员自由选择，在选择后scala再针对他们进行算法层面的特殊优化。因此新老手写的代码无论是在风格还是在执行效率上都会有很大的差异，并且scala不同于ruby，它追求速度（据说ruby因为追求好玩被推特放弃了，现在推特的后台用的是scala和java的组合）。他们的优化集中在编译器的层面，如Miniboxing编译器插件可以让所有的原生类泛型再也不用自动装拆箱从而提高运行效率。另外还有一个特点就是宏macro的使用，macro属于元编程的范畴，所以接下来我们来说说元编程

## 元编程

除了代码之外的数据叫做元数据，比如你写一个类定义里面的数据。元编程就是将定义动态逻辑化，依靠架构的设计来实现小小的修改去做完全不同的事情。java的反射，osgi，spring都用到了这种思想

元编程有很好的拓展性，但是过度的拓展性又会加大开发难度，所以需要好好平衡。Scala就在平衡上做的不错，既提供了大量原生方法和数据结构，又可以通过重构来实现速度上的提升

## java和scala是什么关系呢

说起java，有三个概念经常被提起，JDK是语言软件开发工具包，JDK的安装目录下有一个JRE目录。JRE是java运行环境，不包括编译器和调试器，包括bin和lib文件夹，bin是JVM（虚拟机）标准实现，lib是JVM工作需要的类库。运行的时候源程序.java文件被编译器编译成.class字节码文件，然后进入类装载器，字节码校验器，解释器，最后到操作系统平台执行

scala也符合JVM字节码规范，可以编译成字节码在JVM上运行，此外，它还可以调用所有java的类库，所以关系还是比较紧密的

## Spark和hadoop

scala表达能力强，适合写处理数据，长期运行，吞吐量比较大的服务，除了做后端开发之外，它还有一个重要的方向就是大数据。说到大数据，spark和hadoop一定是最常被提起的



## Spark MLlib

这是一个可拓展的机器学习库，机器学习广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域

机器学习的基本结构是环境，知识库和执行部分。环境向学习部分提供某些信息，学习部分利用这些信息修改知识库，增进执行部分的效能，继续反馈

spark.mllib包中提供的主要API，spark.ml包中提供的构建机器学习工作流的高层次的API

> 局部向量：分为密集向量和稀疏向量
>
> 标记点：

